{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcdac97-b91d-47fd-a8d5-d7a1e22f0d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeb3f742-7c95-49a3-b8ec-92f5b32edfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Training_images/sujith.jpg\")\n",
    "#starting counter \n",
    "#a=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50e0939f-76d6-47f7-a33e-61dbc2445d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to identify face locations 42.42343020439148\n"
     ]
    }
   ],
   "source": [
    "#face_locations = face_recognition.face_locations(img)\n",
    "#b=time.time()\n",
    "#print(\"time taken to identify face locations \"+ str(b-a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d96e606-d9f4-460d-80c9-52496cb453b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to encode faces 0.1760540008544922\n"
     ]
    }
   ],
   "source": [
    "#face_encodings = face_recognition.face_encodings(img, face_locations)\n",
    "#c=time.time()\n",
    "#print(\"time taken to encode faces \"+str(c-b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2f50910-c839-458d-824e-7f4a7bc540d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#known_names=os.listdir(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Training_images\")\n",
    "#known_names.remove(\".DS_Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aec6318-e057-4855-b291-80d47a902784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dipam.jpg',\n",
       " 'aman.jpg',\n",
       " 'dhruv.jpg',\n",
       " 'sujith.jpg',\n",
       " 'bhunia.jpg',\n",
       " 'data.pkl',\n",
       " 'Piyush.jpg']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#known_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d36b5ee-2762-44ff-8f72-9c24cb6e7eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename=\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Training_images/data.pkl\"\n",
    "#face_pkl=open(filename,\"rb\")\n",
    "#known_data=pkl.load(face_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5437a137-a8b7-4e0d-9058-92f979b98079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sujith.jpg']\n"
     ]
    }
   ],
   "source": [
    "recognised_faces=[]\n",
    "for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        # Try to match the face with the known faces\n",
    "        matches = face_recognition.compare_faces(known_data, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # Find the best match\n",
    "        face_distances = face_recognition.face_distance(known_data, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_names[best_match_index]\n",
    "            recognised_faces.append(name)\n",
    "print(recognised_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e5665-d9a1-4f80-a41d-eacc7d643077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d997bc5-f8c0-41fd-b275-e5d036af98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory = r'/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Training_images'\n",
    "#os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7eb2e9c8-453a-4960-b31d-66b1eb4dcb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "#\n",
    "#videoCaptureObject = cv2.VideoCapture(0)\n",
    "#result = True\n",
    "#while(result):\n",
    "#    ret,frame = videoCaptureObject.read()\n",
    "#    cv2.imshow('Capturing Video',frame)\n",
    "#    cv2.imwrite(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/NewPicture.jpg\",frame)\n",
    "#    result = False\n",
    "#videoCaptureObject.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c65f3b-6f5e-4b52-99e6-9513a181be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "############------------------ UPDATE-1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0fa8b86-7aa0-4b23-8059-0caa4315f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2049ead0-18ab-41dc-a719-ac54e3244ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Training_images/data.pkl\"\n",
    "face_pkl=open(filename,\"rb\")\n",
    "known_data=pkl.load(face_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07c7fbc2-1aee-484a-9986-065a2d2e97cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screenshot taken\n",
      "screenshot taken\n",
      "screenshot taken\n",
      "screenshot taken\n",
      "screenshot taken\n",
      "escape hit, closing the app\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cam = cv2.VideoCapture(0)\n",
    "# let's assume the number of images gotten is 0\n",
    "img_counter = 0\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print('failed to grab frame')\n",
    "        break\n",
    "    cv2.imshow('test', frame)\n",
    "    #to get continuous live video feed from my laptops webcam\n",
    "    k  = cv2.waitKey(1)\n",
    "    # Here the programe waits for the key to be pressed and return the key code \n",
    "    \n",
    "    # KEY CODE OF \"ESC\" is 27\n",
    "    \n",
    "    # KEY CODE OF \"Space\" is 32\n",
    "    \n",
    "    # SO , Therfore if the escape key is been pressed, the app will stop\n",
    "    \n",
    "    if k == 27:\n",
    "        print('escape hit, closing the app')\n",
    "        break\n",
    "    # if the spacebar key is been pressed\n",
    "    \n",
    "    # screenshots will be taken\n",
    "    \n",
    "    elif k  == 32:\n",
    "        \n",
    "        # the format for storing the images scrreenshotted\n",
    "        img_name =\"capture\"+str(img_counter)+\".jpg\"\n",
    "        loc=\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/\"+img_name\n",
    "        # saves the image as a png file\n",
    "        cv2.imwrite(loc, frame)\n",
    "        print('screenshot taken')\n",
    "        # the number of images automaticallly increases by 1\n",
    "        img_counter += 1\n",
    "\n",
    "# release the camera\n",
    "cam.release()\n",
    "\n",
    "# stops the camera window\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a87b796f-d78c-40f3-8432-47fb971d4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "pic_all=glob.glob(os.path.join(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured\", '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c04bf3ac-100f-4970-a1d7-ac46ad6c27f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/T1.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/T0.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/T2.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/T3.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/T6.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/T4.jpg',\n",
       " '/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Captured/T5.jpg']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d9831fe-e662-4e07-80e1-92337035c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_names=os.listdir(\"/Users/sujith/Desktop/dp_project/Face-Recognition-Attendance-Projects-main/Training_images\")\n",
    "known_names.remove(\".DS_Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7201ed8-c4c3-47db-bee8-ddb6f0116336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to identify face locations 1.3692409992218018\n",
      "time taken to encode faces 0.05676698684692383\n",
      " \n",
      "time taken to identify face locations 1.2272758483886719\n",
      "time taken to encode faces 0.022984981536865234\n",
      " \n",
      "time taken to identify face locations 1.2449088096618652\n",
      "time taken to encode faces 0.022683143615722656\n",
      " \n",
      "time taken to identify face locations 1.2336900234222412\n",
      "time taken to encode faces 0.02292609214782715\n",
      " \n",
      "time taken to identify face locations 1.2480268478393555\n",
      "time taken to encode faces 0.00011110305786132812\n",
      " \n",
      "time taken to identify face locations 1.228266954421997\n",
      "time taken to encode faces 0.021464824676513672\n",
      " \n",
      "time taken to identify face locations 1.2243399620056152\n",
      "time taken to encode faces 0.02242302894592285\n",
      " \n",
      " \n",
      " \n",
      "['sujith.jpg']\n"
     ]
    }
   ],
   "source": [
    "recognised_faces=[]\n",
    "for i in pic_all:\n",
    "    #starting counter \n",
    "    a=time.time()\n",
    "    img=cv2.imread(i)\n",
    "    \n",
    "    \n",
    "    face_locations = face_recognition.face_locations(img)\n",
    "    b=time.time()\n",
    "    print(\"time taken to identify face locations \"+ str(b-a))\n",
    "    \n",
    "    \n",
    "    face_encodings = face_recognition.face_encodings(img, face_locations)\n",
    "    c=time.time()\n",
    "    print(\"time taken to encode faces \"+str(c-b))\n",
    "    print(\" \")\n",
    "    \n",
    "    recognised_faces=[]\n",
    "    for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        # Try to match the face with the known faces\n",
    "        matches = face_recognition.compare_faces(known_data, face_encoding)\n",
    "        #name = \"Unknown\"\n",
    "\n",
    "        # Find the best match\n",
    "        face_distances = face_recognition.face_distance(known_data, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_names[best_match_index]\n",
    "            recognised_faces.append(name)\n",
    "unique_faces=list(set(recognised_faces))\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print(unique_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df437d-8477-4c1b-aad3-984063b950f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
